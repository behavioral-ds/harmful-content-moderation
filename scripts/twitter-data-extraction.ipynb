{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "chubby-knight",
   "metadata": {},
   "source": [
    "<b>Libraries</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "august-enemy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numerous-escape",
   "metadata": {},
   "source": [
    "<b>Twitter API access for academic research</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cordless-techno",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import api_key, api_key_secret, access_token, access_token_secret, bearer_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sharing-forest",
   "metadata": {},
   "source": [
    "<b>Definition of search queries</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "martial-schema",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data extracted on 20th of March 2023\n",
    "\n",
    "#climatescam\n",
    "search_query = 'lang:en (#climatescam)'\n",
    "save_file = \"../data/twitter_climatescam_hashtag.pkl\"\n",
    "\n",
    "#americafirst\n",
    "# search_query = 'lang:en (#americansfirst OR #americafirst)'\n",
    "# save_file = \"../data/twitter_americafirst_hashtag.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "familiar-universal",
   "metadata": {},
   "source": [
    "<b>Extract data</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "still-twenty",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = tweepy.Client(bearer_token, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "civic-treat",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Sleeping for 9 seconds.\n",
      "Rate limit exceeded. Sleeping for 18 seconds.\n"
     ]
    }
   ],
   "source": [
    "# Warning: Due to the Twitter API time limits this command will take some time\n",
    "\n",
    "tweet_object_list = []\n",
    "\n",
    "for tweet_object in tweepy.Paginator(client.search_all_tweets, \n",
    "                                     query = search_query,\n",
    "                                     user_fields = ['username', \n",
    "                                                    'public_metrics', \n",
    "                                                    'description', \n",
    "                                                    'location'],\n",
    "                                     tweet_fields = ['created_at', \n",
    "                                                     'geo', \n",
    "                                                     'public_metrics', \n",
    "                                                     'text', \n",
    "                                                     'conversation_id',\n",
    "                                                     'possibly_sensitive'],\n",
    "                                     expansions = ['author_id', 'referenced_tweets.id'],\n",
    "                                     start_time = '2022-07-01T00:00:00Z',\n",
    "                                     end_time = '2023-01-01T00:00:00Z',\n",
    "                                     max_results=500):\n",
    "    time.sleep(1)\n",
    "    \n",
    "    tweet_object_list.append(tweet_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "recorded-parliament",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_user_tweet_attributes(\n",
    "    tweet_object_list: list\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate dataframe include tweet and author (user) information\n",
    "    \"\"\"\n",
    "\n",
    "    result = []\n",
    "\n",
    "    user_dict = {}\n",
    "    \n",
    "    referenced_dict = {}\n",
    "\n",
    "    for response in tweet_object_list:\n",
    "        # Take all of the users, and put them into a dictionary of dictionaries with the info we want to keep\n",
    "        if response is not None:\n",
    "            try:\n",
    "                for user in response.includes['users']:\n",
    "                    user_dict[user.id] = {'username': user.username, \n",
    "                                          'followers': user.public_metrics['followers_count'],\n",
    "                                          'tweets': user.public_metrics['tweet_count'],\n",
    "                                          'description': user.description,\n",
    "                                          'location': user.location}\n",
    "\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "\n",
    "            try:\n",
    "                for tweet in response.includes['tweets']:\n",
    "                    referenced_dict[tweet.id] = tweet.text\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            if response.data is not None:\n",
    "                for tweet in response.data:\n",
    "                    # For each tweet, find the author's information\n",
    "\n",
    "                    try:\n",
    "                        author_info = user_dict[tweet.author_id]\n",
    "                        # Put all of the information we want to keep in a single dictionary for each tweet\n",
    "\n",
    "                        if not tweet.referenced_tweets:\n",
    "                            text = tweet.text\n",
    "                            status = 'post'\n",
    "                        else:\n",
    "                            status = tweet.referenced_tweets[0].type\n",
    "                            if tweet.referenced_tweets[0].id in referenced_dict:\n",
    "                                text = referenced_dict[tweet.referenced_tweets[0].id]\n",
    "                            else:\n",
    "                                text = tweet.text\n",
    "\n",
    "                        result.append({'author_id': tweet.author_id,\n",
    "                                       'id': tweet.id,\n",
    "                                       'status': status,\n",
    "                                       'username': author_info['username'],\n",
    "                                       'conversation_id': tweet['conversation_id'],\n",
    "                                       'author_followers': author_info['followers'],\n",
    "                                       'author_tweets': author_info['tweets'],\n",
    "                                       'author_description': author_info['description'],\n",
    "                                       'author_location': author_info['location'],\n",
    "                                       'text': text,\n",
    "                                       'created_at': tweet.created_at,\n",
    "                                       'retweets': tweet.public_metrics['retweet_count'],\n",
    "                                       'replies': tweet.public_metrics['reply_count'],\n",
    "                                       'likes': tweet.public_metrics['like_count'],\n",
    "                                       'quote_count': tweet.public_metrics['quote_count'],\n",
    "                                       'possibly_sensitive': tweet['possibly_sensitive']\n",
    "                                      })\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "    df = pd.DataFrame(result)\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = extract_user_tweet_attributes(tweet_object_list=tweet_object_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "handled-identity",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(save_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
